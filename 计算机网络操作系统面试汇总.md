# 计算机网络/操作系统面试汇总

- [计算机网络/操作系统面试汇总](#计算机网络操作系统面试汇总)
  - [计算机操作系统](#计算机操作系统)
    - [进程和线程的区别](#进程和线程的区别)
    - [死锁概念、产生条件、如何避免](#死锁概念产生条件如何避免)
    - [虚拟内存概念](#虚拟内存概念)
    - [线程池怎么实现](#线程池怎么实现)
    - [进程间通信方式（分点陈述、介绍自己最熟悉的一种）](#进程间通信方式分点陈述介绍自己最熟悉的一种)
    - [共享内存通过什么实现](#共享内存通过什么实现)
    - [栈区和堆区靠什么区分](#栈区和堆区靠什么区分)
    - [栈区自动管理靠什么实现](#栈区自动管理靠什么实现)
    - [一个线程上的栈有多大](#一个线程上的栈有多大)
    - [并发、串行、并行](#并发串行并行)
    - [分页管理 ｜ 分段管理](#分页管理--分段管理)
    - [异步和线程池的区别](#异步和线程池的区别)
    - [内存对齐](#内存对齐)
    - [给两个函数参数是结构体指针和普通的传参哪个好](#给两个函数参数是结构体指针和普通的传参哪个好)
  - [计算机网络](#计算机网络)
    - [TCP 三次握手、四次挥手](#tcp-三次握手四次挥手)
    - [TCP 和 UDP 区别](#tcp-和-udp-区别)
    - [TCP 如何保证可靠传输](#tcp-如何保证可靠传输)
    - [TCP 拥塞控制](#tcp-拥塞控制)
    - [TCP 流量控制工作流程：](#tcp-流量控制工作流程)
    - [Time wait default 值是多少](#time-wait-default-值是多少)
    - [TCP Fin\_wait\_1 是哪个阶段](#tcp-fin_wait_1-是哪个阶段)
    - [HTTP 各种参数作用 请求头有哪些，包含什么信息](#http-各种参数作用-请求头有哪些包含什么信息)
    - [HTTP 不同状态码](#http-不同状态码)
    - [HTTP 缓存机制](#http-缓存机制)
    - [GET 和 POST 区别](#get-和-post-区别)
    - [cookie 和 token](#cookie-和-token)
    - [浏览器存储分为哪些形式](#浏览器存储分为哪些形式)
    - [localStorage、sessionStorage、cookie 区别](#localstoragesessionstoragecookie-区别)
    - [浏览器输入 URL 地址到显示主页的过程](#浏览器输入-url-地址到显示主页的过程)
    - [CDN 内容分发网络](#cdn-内容分发网络)
    - [家庭局域网（LAN）IP 地址与外部网络（例如公网）IP 地址区别](#家庭局域网lanip-地址与外部网络例如公网ip-地址区别)
    - [ARQ 协议](#arq-协议)
    - [HTTP/1.0 1.1 2.0 3.0 区别](#http10-11-20-30-区别)
    - [SYN flood 攻击](#syn-flood-攻击)
    - [HTTP 和 HTTPS 区别 （加密过程）](#http-和-https-区别-加密过程)
    - [抓包为什么能抓到 https 的包](#抓包为什么能抓到-https-的包)
    - [发送方与接收方的滑动窗口分为哪几部分](#发送方与接收方的滑动窗口分为哪几部分)

## 计算机操作系统

### 进程和线程的区别

进程（Process）和线程（Thread）是操作系统中用于执行任务的两种基本方式

1. **定义**：
   - 进程：进程是计算机中的一个独立执行单元，它拥有独立的内存空间和系统资源。每个进程都有自己的地址空间，不同进程之间的内存是隔离的。
   - 线程：线程是进程内的一个执行单元，多个线程共享同一个进程的内存空间和系统资源。线程是进程内的轻量级执行流。
2. **创建和销毁开销**：
   - 进程：创建和销毁进程通常比较耗费系统资源，因为需要分配和释放独立的内存空间。
   - 线程：创建和销毁线程相对较轻量，因为它们共享进程的资源。
3. **通信**：
   - 进程：不同进程之间的通信需要额外的机制，如管道、消息队列、共享内存等。
   - 线程：线程之间可以直接共享进程内的数据，通信更为简单。
4. **并发性**：
   - 进程：进程之间是相互独立的，多个进程并发执行，可以利用多核处理器的性能。
   - 线程：线程在同一个进程内并发执行，可以充分利用进程内的资源，但通常受限于单个核心的执行。
5. **稳定性**：
   - 进程：由于进程间的隔离，一个进程的崩溃通常不会影响其他进程。
   - 线程：一个线程的错误可能导致整个进程崩溃，因为它们共享相同的进程内存空间。
6. **切换开销**：
   - 进程：进程切换（上下文切换）的开销较大，因为需要保存和恢复进程的整个状态。
   - 线程：线程切换的开销较小，因为它们共享进程的地址空间和大部分状态。
7. **适用场景**：
   - 进程：适用于需要隔离和独立运行的任务，如不同的应用程序、服务或虚拟机。
   - 线程：适用于并发执行的任务，如多线程编程、图形界面程序等。

### 死锁概念、产生条件、如何避免

死锁(Deadlock)是指在多任务环境下，当两个或更多的任务各自拥有一个资源并且等待获取另一个任务持有的资源时，就会发生的一种状态。涉及的任务无法继续执行，因为每个任务都在等待其他任务释放资源，但是没有任务会释放它的资源，因为它们都在等待。这就形成了一个循环的等待状态，从而导致了死锁。

![image-20231213下午51718041](/Users/zhangyuanpu/Library/Application Support/typora-user-images/image-20231213 下午 51718041.png)

死锁伪代码

```swift
import Foundation

let lock1 = NSLock()
let lock2 = NSLock()

// 线程1
let thread1 = Thread {
    lock1.lock()
    print("Thread 1 locked Lock 1")

    // 延迟一段时间，让线程2也锁定它需要的资源
    Thread.sleep(forTimeInterval: 1.0)

    lock2.lock() // 线程1试图锁定Lock 2，但它已经被线程2锁定了
    print("Thread 1 locked Lock 2")

    lock1.unlock()
    lock2.unlock()
}

// 线程2
let thread2 = Thread {
    lock2.lock()
    print("Thread 2 locked Lock 2")

    // 延迟一段时间，让线程1也锁定它需要的资源
    Thread.sleep(forTimeInterval: 1.0)

    lock1.lock() // 线程2试图锁定Lock 1，但它已经被线程1锁定了
    print("Thread 2 locked Lock 1")

    lock2.unlock()
    lock1.unlock()
}

thread1.start()
thread2.start()
```

在上述示例中，我们创建了两个锁 `lock1` 和 `lock2`，然后分别在两个线程中尝试锁定这两个锁。线程 1 首先锁定 `lock1`，然后尝试锁定 `lock2`，而线程 2 首先锁定 `lock2`，然后尝试锁定 `lock1`。由于线程 1 和线程 2 都在等待对方释放资源，它们将陷入死锁状态，导致程序无法继续执行。

### 虚拟内存概念

虚拟内存是计算机系统内存管理的一种技术，它为用户程序和数据提供了一种“虚拟”的内存视图，这种视图与物理内存的实际结构可能完全不同。虚拟内存的概念和实现原理主要包括以下几个方面：

概念

1. **内存抽象**：虚拟内存通过抽象化处理，使得每个程序都认为自己是在使用一大块连续的内存空间，而实际上这些空间可能在物理内存中是分散的。

2. **内存扩展**：它允许程序使用比物理内存更多的内存空间，通过将部分数据存储在磁盘上（通常是硬盘上的交换空间或分页文件），来扩展可用内存。

实现原理

1. **分页（Paging）**：

   - **内存分割**：物理内存和虚拟内存都被划分为大小相同的块，称为“页”（在虚拟内存中）和“页框”（在物理内存中）。
   - **页表**：操作系统维护一个页表来记录虚拟页与物理页框之间的映射关系。
   - **地址转换**：当程序访问虚拟地址时，硬件或操作系统负责将其转换为相应的物理地址。

2. **分段（Segmentation）**：

   - **内存分割为段**：内存被分为逻辑上的段，如代码段、数据段等。
   - **段表**：操作系统使用段表来管理这些段，记录它们在物理内存中的位置和大小。
   - **地址转换**：将程序中的段引用转换为物理内存地址。

3. **页面置换算法**：

   - 当物理内存不足以存储所有活跃的页时，系统会根据特定的算法（如最近最少使用（LRU）算法、先进先出（FIFO）算法等）选择某些页将其移出物理内存，以空出页框载入新的页。

4. **缺页中断（Page Fault）**：

   - 当程序试图访问一个不在物理内存中的页时，会触发缺页中断。操作系统接管，从磁盘中加载所需页到物理内存，然后恢复程序执行。

5. **交换空间/分页文件（Swap Space/Page File）**：

   - 一个特定的磁盘区域用于存储不常用的内存页。当这些页需要被重新加载到物理内存时，可以从这个区域检索。

### 线程池怎么实现

### 进程间通信方式（分点陈述、介绍自己最熟悉的一种）

进程间通信（Inter-Process Communication，IPC）是指不同进程之间进行数据交换和共享信息的方式。在操作系统中，有多种 IPC 的实现方式，以下是一些常见的 IPC 方式：

1. **管道（Pipe）：**
   - **描述：** 管道是一种半双工的通信方式，具有固定的读写方向。它可以用于具有亲缘关系的进程之间的通信。
2. **消息队列（Message Queues）：**
   - **描述：** 消息队列是一种进程间通信的机制，允许将消息发送到队列中，由其他进程从队列中接收。
   - **优点：** 异步通信、可以在不同步方向上传递较大量的数据。
   - **适用场景：** 适用于不要求实时性的通信。
3. **信号（Signals）：**
   - **描述：** 信号是一种在进程之间传递信息的简单机制，通常用于通知进程发生了某个事件。
   - **特点：** 信号是异步的，不提供数据传输机制，主要用于通知。
4. **共享内存（Shared Memory）：**
   - **描述：** 共享内存允许多个进程访问同一块物理内存，从而实现数据的共享。
   - **优点：** 高效、适用于大量数据的快速交换。
   - **缺点：** 需要同步机制，防止多个进程同时修改共享内存。
5. **信号量（Semaphores）：**
   - **描述：** 信号量是一种用于进程间同步的机制，通常用于控制对共享资源的访问。
   - **特点：** 可以用于进程的同步和互斥。
6. **套接字（Sockets）：**
   - **描述：** 套接字是一种在网络中用于进程间通信的方式，但也可以用于同一台机器上的进程通信。
   - **优点：** 跨网络、可在不同机器上通信。
   - **缺点：** 相对于其他 IPC 方式，实现相对复杂。
7. **文件映射（Memory-Mapped Files）：**
   - **描述：** 文件映射允许多个进程共享同一个文件，并在内存中创建一个映射区，通过该区域进行通信。
   - **适用场景：** 适用于需要共享大量数据的场景。

### 共享内存通过什么实现

### 栈区和堆区靠什么区分

栈区（Stack）和堆区（Heap）是内存的两个主要区域，它们在内存管理中有不同的用途和分配方式。这两个区域在多线程环境中的区分主要涉及到线程的私有性和共享性。

**栈区：**

1. **线程私有：** 每个线程都有自己的栈空间，栈区是线程私有的。每个线程都会在栈上维护自己的方法调用栈。

2. **局部变量：** 用于存储函数调用中的局部变量、函数参数、方法调用的上下文等。每个线程的栈空间是独立的，不同线程之间不共享栈。

3. **生命周期：** 局部变量的生命周期与其所在的方法调用相关，当方法调用结束时，局部变量在栈上自动被销毁。

4. **分配速度快：** 栈上的内存分配和释放速度较快，因为它是由编译器自动管理的。

**堆区：**

1. **线程共享：** 堆区是进程的共享资源，被所有线程共享。多个线程可以同时访问堆。

2. **动态分配：** 用于存储程序运行时动态分配的数据，例如通过 `new` 或 `malloc` 分配的内存。堆上的内存需要手动进行管理，包括分配和释放。

3. **生命周期：** 堆上的内存生命周期不与方法调用相关，需要显式地进行分配和释放，否则可能发生内存泄漏。

4. **分配速度较慢：** 堆上的内存分配速度相对较慢，因为需要在运行时进行动态分配。

**多线程环境下的区分：**

- **栈区：** 每个线程有自己的栈空间，栈是线程私有的，不同线程之间的栈空间是独立的，互不影响。

- **堆区：** 堆是进程的共享资源，被所有线程共享。多个线程可以同时访问和操作堆上的内存。

### 栈区自动管理靠什么实现

栈通常是由操作系统自动管理的，用于存储函数的局部变量、函数调用的参数和函数调用的返回地址。每个线程都有其自己的栈，栈的大小在程序运行时通常是固定的或受限制的。栈内存的分配和释放是由操作系统的调用栈机制控制的，遵循"先进后出"的原则。

### 一个线程上的栈有多大

一个线程上的栈大小是由操作系统确定的，并且可以在程序运行时根据系统的配置和限制进行调整。栈的大小通常是固定的，但可以根据需要进行调整。

在多数操作系统中，每个线程都有其自己的栈。栈的大小取决于操作系统的设置和应用程序的需求。一般情况下，栈的大小在几 MB 到几十 MB 之间，这足以满足大多数应用程序的需要。

需要注意的是，栈的大小不应该过于小，否则可能导致栈溢出，这是一种内存错误，通常会导致程序崩溃。另一方面，栈也不应该过于大，因为每个线程的栈都需要占用内存，如果栈太大，可能会导致内存资源不足。

### 并发、串行、并行

1.  **并发（Concurrency）：**
    - 并发是指两个或多个任务在时间上重叠进行，但不一定同时执行。在并发中，多个任务之间可以是交替执行的，通过操作系统的时间片轮转或事件驱动等机制，实现看似同时执行的效果。
    - 并发强调任务之间的交替和互相切换，不同任务之间通过并发的方式实现共享资源、提高系统吞吐量等目标。
2.  **串行（Sequential）：**
    - 串行是指一个任务按照指定的顺序执行，一次执行一个步骤。在串行执行中，任务按照顺序一个接一个地完成，没有交叉和并发。
    - 串行执行是最基本、最简单的执行方式，适用于一些顺序执行的任务。
3.  **并行（Parallel）：**
    - 并行是指两个或多个任务在同一时刻执行。在并行中，不同的任务同时进行，每个任务都有独立的处理单元。
    - 并行强调任务之间真正的同时执行，通常需要多个处理单元或者多核处理器来实现。

### 分页管理 ｜ 分段管理

**分页:** 分页是一种内存管理技术，它将虚拟内存空间和物理内存空间分割成固定大小的单元，我们称这个单元为"页"。分页是为了解决内存碎片的问题，因为分页可以让每一块内存空间都被有效利用。分页是透明的，也就是说这个过程对用户程序是不可见的。用户程序看到的仍然是一个连续的内存空间。

**分段:** 对于分段，其主要目标是将程序自身的逻辑结构反映到物理存储器中去。在逻辑上，程序员根据代码的逻辑关系将程序分成大小不等的段，比如说代码段、数据段等。然后根据程序的需要，将这些段加载到内存中。分段是可见的，也就是说程序员在编写程序的时候可以看到分段的效果。

1.  目的：分段是为了反映程序的逻辑结构，分页是为了更有效地使用内存，并减少内存碎片。

2.  大小：页的大小是固定的，机器系统决定了页的大小，且各个系统的页面大小不一样。段的大小是可
    变的，由程序的逻辑结构决定。

3.  可见性：用户程序可以看到分段的结果，但是看不到分页的结果。在实际的系统中，分页和分段往往并用，这种技术被称为段页式管理。

### 异步和线程池的区别

异步编程和线程池是用于处理并发任务的两种不同方法，它们有以下主要区别：

1. **执行方式：**

   - 异步编程：在异步编程中，任务的执行是非阻塞的，即任务在后台执行，不会阻塞主线程或程序的执行。异步编程通常使用回调函数、Promise、async/await 等机制来管理任务的执行顺序。
   - 线程池：线程池是一组预先创建的线程，用于执行并发任务。每个任务都可以分配给线程池中的一个线程来执行。线程池中的线程通常是同步执行任务，任务按照队列的方式依次执行。

2. **并发级别：**

   - 异步编程：异步编程可以实现高并发，但通常在单个线程中处理任务，因此需要谨慎处理可能阻塞线程的操作。
   - 线程池：线程池可以通过并发执行多个任务来提高并发级别，每个任务分配给线程池中的不同线程执行，可以充分利用多核处理器的性能。

3. **资源开销：**

   - 异步编程：异步编程通常需要较少的线程，因为任务在单个线程中执行。这可以减少线程管理和上下文切换的开销。
   - 线程池：线程池需要创建和维护多个线程，因此会占用更多的系统资源，特别是在大规模的并发应用中。

4. **适用场景：**
   - 异步编程：适用于 I/O 密集型任务，如网络请求、文件操作、数据库查询等。异步编程可以避免线程等待，提高系统的响应性。
   - 线程池：适用于 CPU 密集型任务，如计算密集型的算法或数据处理。线程池可以充分利用多核处理器，并提高计算性能。

### 内存对齐

内存对齐是指在分配和访问内存时，数据结构的起始地址是内存对齐要求的倍数。通常，数据类型在内存中的地址应该是其大小的整数倍。内存对齐是为了提高计算机系统的性能和效率，并确保存储器访问的高效性。

为什么要内存对齐？

1. **硬件要求：** 许多计算机体系结构对于不同数据类型的访问有硬件对齐的要求。例如，许多处理器要求访问不同数据类型的地址是其大小的整数倍，否则可能导致性能下降或者甚至出错。

2. **性能优化：** 内存对齐可以提高内存访问的效率。当数据结构被对齐时，可以通过更快的内存读写操作来访问数据。未对齐的访问可能需要多次内存访问，导致性能下降。

内存对齐的原则：

1. **基本原则：** 数据的地址应该是其大小的整数倍。

2. **结构体对齐：** 结构体的对齐要求通常是其最大基本数据类型的大小。例如，如果结构体包含一个`double`和一个`char`，那么结构体的对齐要求通常是`double`的大小。

3. **指针对齐：** 指针的地址通常要满足指针指向的数据类型的对齐要求。例如，指向`int`的指针通常需要 4 字节对齐。

4. **编译器指令：** 编译器通常提供一些指令或者编译选项来调整对齐规则。例如，GCC 编译器可以使用`__attribute__((aligned(n)))`来指定对齐方式。

示例：

考虑一个结构体的例子：

```c
struct Example {
    char a;      // 1字节
    int b;       // 4字节
    double c;    // 8字节
};
```

在一个典型的对齐规则下，该结构体的对齐要求可能是 8 字节，因为`double`的大小是 8 字节。如果不对齐，可能会导致`int`和`double`类型的变量未对齐，从而降低内存访问效率。通过对齐，结构体的内存布局可能是：

```
a______padding1_padding2_bccccccccccccccccpadding3_padding4
```

这里的`padding`是为了保证对齐而插入的填充字节。

### 给两个函数参数是结构体指针和普通的传参哪个好

选择函数参数传递方式（结构体指针 vs. 直接传参）通常取决于多个因素，包括结构体的大小、复杂度、是否需要修改结构体内容、性能要求等。以下是一些考虑因素：

**传递结构体指针的优点：**

1. **避免复制：** 传递结构体指针避免了结构体的复制，尤其是对于大型结构体来说，复制可能会产生较大的性能开销。

2. **修改原结构体：** 如果函数需要修改结构体的内容，通过传递结构体指针可以直接在原结构体上进行修改，而不需要返回修改后的结构体。

3. **内存效率：** 对于大型结构体，通过指针传递可以减少栈上的内存占用。

**直接传递结构体的优点：**

1. **简洁性：** 直接传递结构体参数可以使函数调用更加简洁，不需要显式地取地址或传递指针。

2. **避免指针操作：** 传递结构体指针可能需要在函数内进行指针操作，而直接传递结构体参数可以避免这些操作。

3. **尺寸小：** 对于小型结构体，结构体的大小可能不会对性能产生显著影响，而且传递结构体参数更为方便。

**选择的原则：**

1. **结构体大小：** 对于小型结构体，直接传递可能更为合适，而对于大型结构体，传递指针可能更有效。

2. **是否需要修改：** 如果函数需要修改结构体内容，传递指针是更直接的方式。如果只是读取结构体内容，直接传递可能更为简洁。

3. **性能考虑：** 如果性能是关键因素，可以进行性能测试，看哪种方式更符合性能要求。

4. **一致性：** 与代码库中的习惯保持一致，以提高代码的一致性和可读性。

## 计算机网络

### TCP 三次握手、四次挥手

### TCP 和 UDP 区别

1.  连接性：TCP 是面向连接的协议，数据传输前需要先建立连接，且保持连接状态直到传输完成；而 UDP 是面
    向无连接的协议，数据传输前不需要建立连接，直接发送数据包。
2.  可靠性：T℃P 提供可靠的数据传输服务，数据传输时进行错误检测和校验，确保数据的可靠传输和完整性；
    而 UDP 则不提供可靠传输服务，数据传输过程中可能丢失、重复或乱序。
3.  速度：UDP 传输速度比 TCP 更快，因为它不需要进行错误校验和重传等操作，数据发送和接收的效率更高。
4.  流量控制：TCP 具有流量控制机制，可以根据网络拥塞情况动态调整发送数据的速度，以避免网络拥塞；而
    UDP 则不支持流量控制，可能会造成网络拥塞。
    总的来说，TCP 更适合要求可靠性、稳定性较高的场景，如传输邮件、网页等；而 UDP 更适合实时性要求较高的场景，如音视频传输、游戏等。

### TCP 如何保证可靠传输

1.  自动重传：TCP 连接的两端会相互通信，确认已经成功接收到的数据，并且在一定时间内未收到对方
    确认的数据会被重新发送，以此来保证数据包被成功传输。
2.  滑动窗口机制：TCP 连接可以通过滑动窗口机制来进行流量控制。接收端会通过发送窗口大小告知发送端接
    收缓冲区的可用空间，以此来避免发送过多数据导致接收端无法处理过来。
3.  超时重传：TCP 协议会对每个数据包设置一个超时计时器，在一定时间内未收到对方确认的数据会被重新发
    送，在网络丢包或者数据包被篡改的情况下，TCP 会通过超时重传机制来保证数据能够被成功传输。
4.  拥塞控制：TCP 连接通过对网络拥塞的检测和流量控制来避免网络拥塞。每个 TCP 连接会维护一个拥塞窗
    口，在网络拥塞的情况下，会自适应地调整发送的数据量，以此来降低拥塞的出现率。
    由于 TCP 协议的可靠性，它已经成为了互联网上应用最广泛的可靠传输协议之一。例如，网页浏览、邮件传输、文件下载等应用程序的传输都是通过 TCP 来完成的。

### TCP 拥塞控制

1.  慢启动(Slow Start):在开始发送数据之前，缓慢增加数据发送量，避免一开始就发送大量数据导致网络拥塞。
2.  拥塞避免(Congestion Avoidance):在网络中出现拥塞时，控制发送数据的速率。
3.  快速恢复(Fast Retransmit):在发生丢包时，避免等待重传计时器到期，直接重传丢失的数据段。
4.  快速重传(Fast Recovery)):在发生丢包时，仅重传丢失的数据段，而不是之前的所有数据段。
5.  连接迁移(Connection Migration):在移动设备切换到其他接入网络时，避免网络拥塞和丢包。总体来
    说，TCP 拥塞控制的目的是避免网络拥塞，保证数据传输的可靠性和效率。

### TCP 流量控制工作流程：

1. **握手时确定初始窗口大小：**

   - 在 TCP 的三次握手过程中，双方会协商初始的窗口大小。

2. **动态调整窗口大小：**

   - 接收方通过 TCP 的选项字段中的窗口字段告知发送方当前的接收窗口大小。
   - 发送方根据接收方的窗口大小调整发送窗口大小。

3. **接收方向发送窗口滑动：**

   - 当接收方处理了部分数据后，可以通过 TCP 的确认（ACK）来告知发送方可以接收更多数据，从而滑动接收窗口。

4. **防止溢出：**
   - 发送方发送的数据不能超过接收方的窗口大小，以防止数据溢出和丢失。

TCP 窗口字段：

在 TCP 头部中，有一个称为窗口字段的 16 位字段，用于指示接收方的窗口大小。发送方根据接收方的窗口大小来控制发送的数据量，以避免超过接收方的处理能力。

流量控制的目标是优化网络性能，防止数据的丢失和拥塞。通过动态调整发送和接收窗口大小，TCP 流量控制确保在网络中的各种条件下，数据能够以可靠的方式传输。

### Time wait default 值是多少

在 TCP 连接中，TIME_WAIT 状态是一个表示关闭连接的状态，它在关闭连接后保持一段时间。TIME_WAIT 状态的目的是为了确保连接中的所有数据段都已经被正确接收，从而防止后续出现混乱的重复数据。

TIME_WAIT 状态的持续时间由操作系统内核参数控制，不同的操作系统和内核版本可能会有不同的默认值。一般情况下，TIME_WAIT 状态的默认持续时间在 30 秒到 2 分钟之间。

### TCP Fin_wait_1 是哪个阶段

### HTTP 各种参数作用 请求头有哪些，包含什么信息

HTTP（Hypertext Transfer Protocol）是一种用于传输超文本的协议，它是互联网中应用最为广泛的协议之一。在 HTTP 请求中，请求头是一个包含了关于客户端请求的各种信息的部分。以下是一些常见的 HTTP 请求头以及它们的作用：

1. **User-Agent:** 表示客户端的标识，用于告知服务器发送请求的客户端信息，通常包括操作系统、浏览器版本等。

2. **Accept:** 告知服务器客户端能够处理的媒体类型，通常用于指定客户端能够接受的响应内容类型。

3. **Content-Type:** 用于指定请求主体的媒体类型，通常在 POST 请求中使用，告知服务器请求主体的数据类型。

4. **Authorization:** 用于向服务器发送身份验证凭证，例如基本身份验证（Basic Authentication）或令牌（Token）等。

5. **Cookie:** 用于在客户端和服务器之间传递会话信息，服务器可以根据 Cookie 识别客户端的会话状态。

6. **Host:** 表示请求的目标服务器的主机名和端口号。

7. **Referer:** 表示请求的来源页面，用于告知服务器当前请求是从哪个页面跳转过来的。

8. **Content-Length:** 表示请求主体的长度，以字节为单位。

9. **If-Modified-Since:** 用于条件请求，告知服务器只有在指定日期之后修改过的资源才会被返回。

10. **Cache-Control:** 用于控制缓存行为，例如指定缓存有效期、是否允许缓存等。

11. **Connection:** 用于控制是否保持持久连接，可以设置为“keep-alive”以保持连接复用。

12. **Accept-Encoding:** 告知服务器客户端能够接受的内容编码方式，例如 gzip、deflate 等。

13. **Accept-Language:** 告知服务器客户端的首选语言，服务器可以根据这个信息来选择合适的响应内容语言。

14. **Origin:** 表示请求的源信息，通常在跨域请求中用于进行预检请求（Preflight Request）。

15. **X-Requested-With:** 通常用于指示请求是否由 Ajax 发起，以便服务器进行相应处理。

以上列举的是一些常见的 HTTP 请求头，它们包含了关于客户端请求的各种信息，可以帮助服务器进行相应的处理和响应。

### HTTP 不同状态码

HTTP 状态码是服务器对客户端请求的响应的一部分，它告诉客户端请求的处理结果。以下是一些常见的 HTTP 状态码：

1xx - 信息性状态码（Informational）

- **100 Continue：** 表示服务器已经接收到请求的头部，并且客户端应该继续发送请求的其余部分。

- **101 Switching Protocols：** 表示服务器已经理解了客户端的请求，并将通过 Upgrade 消息头通知客户端更改协议。

2xx - 成功状态码（Successful）

- **200 OK：** 表示请求成功，通用性的成功状态码。

- **201 Created：** 表示请求已经被成功处理，并且服务器创建了新的资源。

- **204 No Content：** 表示服务器成功处理了请求，但没有返回任何内容。

3xx - 重定向状态码（Redirection）

- **301 Moved Permanently：** 表示被请求的资源已永久移动到新位置。

- **302 Found（或临时移动）：** 表示被请求的资源暂时从不同的 URI 响应请求。

- **304 Not Modified：** 表示客户端发送附带条件的请求，但服务器未满足条件，资源未被修改。

4xx - 客户端错误状态码（Client Error）

- **400 Bad Request：** 表示服务器无法理解客户端的请求，通常由于语法错误。

- **401 Unauthorized：** 表示请求需要用户身份验证。

- **403 Forbidden：** 表示服务器理解请求，但拒绝执行。

- **404 Not Found：** 表示服务器无法找到请求的资源。

5xx - 服务器错误状态码（Server Error）

- **500 Internal Server Error：** 表示服务器遇到了一个未知的错误，无法完成请求。

- **501 Not Implemented：** 表示服务器不支持请求的功能，无法完成请求。

- **502 Bad Gateway：** 表示服务器作为网关或代理，从上游服务器接收到无效的响应。

- **503 Service Unavailable：** 表示服务器当前无法处理请求，通常由于过载或维护。

这只是一些常见的 HTTP 状态码，HTTP/1.1 和 HTTP/2.0 还有其他状态码。状态码提供了一种机制，用于在处理 HTTP 请求时向客户端传递请求的执行结果信息。

### HTTP 缓存机制

HTTP 缓存机制是指浏览器和服务器之间通过 HTTP 协议定义的一种缓存策略，用于减少网络流量，提高网站性能，以及减少服务器负载。HTTP 缓存机制主要分为两种类型：客户端缓存和服务器端缓存。

客户端缓存：

1. **强缓存**：

   - 强缓存是指浏览器直接从本地缓存中获取资源，而不会向服务器发送请求。通常使用响应头中的 `Cache-Control` 和 `Expires` 来指定资源的缓存策略。
   - `Cache-Control` 指令中的 `max-age` 规定了资源被缓存的最长时间，单位是秒。例如，`Cache-Control: max-age=3600` 表示资源在本地缓存中有效期为 3600 秒。
   - `Expires` 是一个 HTTP 头部字段，指定了资源的过期时间，以 GMT 格式的日期/时间表示。例如，`Expires: Wed, 21 Oct 2024 07:28:00 GMT` 表示资源在这个日期时间之后过期。

2. **协商缓存**：
   - 如果资源的强缓存失效，浏览器会向服务器发送请求，服务器会根据资源的最新状态来决定是否返回资源。这个过程称为协商缓存。
   - 协商缓存通常使用响应头中的 `Last-Modified` 和 `If-Modified-Since`，以及 `ETag` 和 `If-None-Match` 来进行判断。
   - 当资源的修改时间（`Last-Modified`）或资源的唯一标识符（`ETag`）与客户端的请求相匹配时，服务器会返回状态码 304，表示资源未发生变化，可以继续使用客户端缓存。

服务器端缓存：

1. **代理服务器缓存**：

   - 代理服务器（如 CDN、反向代理服务器等）可以缓存客户端请求的资源，并在后续请求中直接返回缓存的资源，减轻了源服务器的负载压力。
   - 代理服务器缓存通常使用类似客户端缓存的缓存策略，包括强缓存和协商缓存。

2. **服务器端缓存**：
   - 源服务器也可以缓存动态生成的内容，以减少重复计算和数据库查询等操作，提高响应速度。
   - 服务器端缓存通常使用内存缓存、文件缓存、数据库缓存等技术来实现。

通过合理配置和利用 HTTP 缓存机制，可以有效地降低网络流量、提高网站性能，并减轻服务器负载，从而提升用户体验。

### GET 和 POST 区别

1.  GET 用于获取资源，而 POST 用于提交（或创建） 资源。
2.  GET 请求参数通过 URL 传递，而 POST 请求参数在请求体中传递。
3.  GET 方法只读，不会改变服务器状态，POST 传送实体 (安全方法：GET、HEAD、OPTION，不安全方法，POST、PUT、DELETE)
4.  GET 请求可以被缓存，POST 请求不能被缓存。（可缓存条件， HTTP 方法本身可缓存，响应报文状态码可缓存）
5.  GET URL 有长度限制，POST 没有

### cookie 和 token

`Cookie` 和 `Token` 都是用于在 Web 应用中进行身份验证和会话管理的机制，但它们有一些关键的区别。

**基本概念**

Cookie 的出现是来弥补 HTTP 无状态的问题的，Cookie 可以作为一个状态保存的状态机，用来保存用户的相关登录状态，当第一次验证通过后，服务器可以通过 set-cookie 令客户端将自己的 cookie 保存起来，当下一次再发送请求的时候，直接带上 cookie 即可，而服务器检测到客户端发送的 cookie 与其保存的 cookie 值保持一致时，则直接信任该连接，不再进行验证操作。大致的过程如下图

Token，简单来说，就是类似 cookie 的一种验证信息，客户端通过登录验证后，服务器会返回给客户端一个加密的 token，然后当客户端再次向服务器发起连接时，带上 token，服务器直接对 token 进行校验即可完成权限校验。

**token 出现原因**

Cookie 作为 HTTP 规范，其出现历史久远，因此存在一些历史遗留问题，比如跨域限制等，并且 Cookie 作为 HTTP 规范中的内容，其存在默认存储以及默认发送的行为，存在一定的安全性问题。

相较于 Cookie, token 需要自己存储，自己进行发送，不存在跨域限制，因此 Token 更加的灵活，在安全性上也能够做更多的优化。

从上面对于 Token 和 Cookie 的分析，我们知道了 Cookie 由于存储的内存空间只有 4kb，因此存储的主要是一个用户 id,其他的用户信息都存储在服务器的 Session 中，而 Token 没有内存限制，用户信息可以存储 Token 中，返回给用户自行存储，因此可以看出，采用 Cookie 的话，由于所有用户都需要在服务器的 Session 中存储相对应的用户信息，所以如果用户量非常大，这对于服务器来说，将是非常大的性能压力，而 Token 将用户信息返回给客户端各自存储，也就完全避开这个问题了。

### 浏览器存储分为哪些形式

1. **Cookies（Cookie）**：

   - Cookie 是最古老的一种浏览器存储形式，用于在客户端存储少量的文本数据。它们以键值对的形式存储，并附加在 HTTP 请求头中发送到服务器。
   - Cookies 可以设置过期时间，可以指定域名和路径，还可以设置安全标志和 HTTP Only 标志来增强安全性。

2. **Web Storage**：

   - Web Storage 提供了两种存储方式：LocalStorage 和 SessionStorage。
   - LocalStorage：可以存储较大量的数据（通常为 5MB），数据会永久保存在客户端，除非被清除或被网站手动删除。
   - SessionStorage：只能存储少量数据（通常为 5-10MB），数据在浏览器会话结束时自动清除，关闭窗口或标签页后数据就会丢失。

3. **IndexedDB**：

   - IndexedDB 是浏览器提供的一种客户端数据库，支持存储大量结构化数据。
   - IndexedDB 提供了强大的查询和事务支持，可以在客户端进行高效的数据操作。

4. **Cache Storage**：

   - Cache Storage 是浏览器提供的一种缓存机制，用于存储请求的响应结果。它通常用于存储静态资源（如图片、样式表、脚本等），以提高网站的加载速度。

5. **Session Cookies**：
   - 除了常规的 Cookies 外，浏览器还会自动生成会话 Cookie，它们存储在内存中，并在浏览器会话结束时自动删除。这种类型的 Cookie 只在会话期间有效。

### localStorage、sessionStorage、cookie 区别

1. **数据存储方式**：

   - **localStorage**：提供了一个持久化存储的简单键值对（key-value）存储机制，保存的数据在浏览器关闭后仍然存在，直到被显式删除。
   - **sessionStorage**：提供了与 localStorage 类似的简单键值对存储机制，但数据仅在当前会话期间有效。即当用户关闭浏览器窗口或标签后，数据会被清除。
   - **cookie**：通过 HTTP 报文头部在客户端和服务器之间传递数据，可以设置失效时间，如果没有设置失效时间，cookie 会在浏览器关闭后被删除。

2. **存储大小限制**：

   - **localStorage** 和 **sessionStorage**：通常限制在 5MB 左右，不同浏览器可能有所不同。
   - **cookie**：每个 cookie 的大小限制通常为 4KB，每个域名下的 cookie 数量也有限制。

3. **访问权限**：

   - **localStorage** 和 **sessionStorage**：只能被同源的页面访问，不同页面或标签之间不共享数据。
   - **cookie**：可以设置 cookie 的访问范围，包括同一域名下的所有页面和子域名。

4. **安全性**：

   - **localStorage** 和 **sessionStorage**：数据存储在客户端，相对来说比 cookie 更安全，因为数据不会随着每个 HTTP 请求发送到服务器。
   - **cookie**：cookie 可能会受到跨站脚本攻击（XSS）和跨站请求伪造（CSRF）等攻击。

5. **用途**：
   - **localStorage** 和 **sessionStorage**：适用于需要在客户端存储数据，并且需要长期保存或者在会话期间内共享的场景。
   - **cookie**：适用于需要在客户端和服务器之间传递数据的场景，如用户认证、会话管理等。

### 浏览器输入 URL 地址到显示主页的过程

1.  DNS 域名解析 浏览器 DNS 缓存--> 操作系统 DNS 缓存-->本地 Host 文件查找-->DNS 服务查询-->IP 地址
2.  TCP 连接 浏览器获得域名对应的 IP 地址后请求建立连接，三次握手
3.  客户端发送 HTTP 请求服务器返回 HTTP 报文
4.  浏览器解析渲染页面
5.  四次挥手关闭 TCP 连接

### CDN 内容分发网络

CDN（Content Delivery Network，内容分发网络）是一种分布式服务器系统，用于在全球范围内提供网站内容、媒体文件等静态资源的高效传输和交付服务。CDN 旨在通过将内容缓存到位于全球各地的服务器上，从而减少网络延迟，提高内容传输速度，增强网站性能和用户体验。

CDN 的工作原理通常包括以下几个关键步骤：

1. **内容缓存**：CDN 提供商将网站的静态资源（如 HTML 文件、图像、视频、音频等）缓存到位于全球各地的服务器上。这些服务器被称为边缘节点或边缘服务器。

2. **就近访问**：当用户请求访问网站时，CDN 会通过一系列算法选择最接近用户的边缘节点。这样做可以减少网络延迟和传输时间，提高内容的加载速度。

3. **内容传输**：选定的边缘节点会从缓存中检索所需的内容，并将其传输给用户的设备。如果内容不在边缘节点的缓存中，则边缘节点会向原始服务器请求内容，然后将其缓存并返回给用户。

4. **动态负载均衡**：CDN 系统会动态监控网络流量和服务器负载情况，并根据实时情况调整内容的分发策略，以确保最佳的性能和可用性。

### 家庭局域网（LAN）IP 地址与外部网络（例如公网）IP 地址区别

家庭局域网（LAN）内部设备与外部网络（例如公网）之间访问的 IP 地址通常会有一些区别，这些区别可以通过以下几个方面来说明：

1. **IP 地址范围**：
   - 局域网内部通常使用私有 IP 地址范围，这些 IP 地址是专门用于内部网络使用的，不会在公网上路由。公网访问时，通常使用由互联网服务提供商（ISP）分配的公共 IP 地址。
2. **网络地址转换（NAT）**：
   - 在家庭网络中，通常会使用网络地址转换（NAT）技术，将局域网内部的私有 IP 地址映射到公网上 ISP 分配的公共 IP 地址。这样，局域网内的设备可以通过共享单个公网 IP 地址来访问互联网。
3. **路由器**：
   - 家庭网络通常使用路由器来连接局域网和互联网。路由器在内部网络和外部网络之间充当网关，负责管理数据包的转发。

总之，家庭局域网访问的 IP 地址是内部私有 IP 地址，经过 NAT 转换后访问公网时会使用家庭路由器的公共 IP 地址。而正常访问公网时，会直接使用由 ISP 分配的公共 IP 地址。

### ARQ 协议

### HTTP/1.0 1.1 2.0 3.0 区别

1.0 默认情况下是非持久连接，每个请求/响应周期都需要新的 TCP 连接

1.1 默认情况下是持久连接，管道化通信，多个请求/响应可以共享同一个 TCP 连接，提高性能

2.0 二进制文本压缩算法，避免了 HTTP/1.x 中的队头阻塞问题

3.0 使用了基于 UDP 的 QUIC 协议，而不是 TCP，提高了连接的性能和安全性

### SYN flood 攻击

### HTTP 和 HTTPS 区别 （加密过程）

[HTTPS 是什么？加密原理和证书。SSL/TLS 握手过程\_哔哩哔哩\_bilibili](https://www.bilibili.com/video/BV1KY411x7Jp/?spm_id_from=333.788&vd_source=a11f40747ab601aa19d609bcaa570c76)

**加密过程简要描述：**

1.  **握手阶段：** 客户端向服务器发送一个请求连接，并请求与服务器建立安全连接。服务器会发送自己的数字证书。
2.  **证书验证：** 客户端验证服务器的数字证书。如果证书有效且被信任，客户端生成一个用于后续通信的随机对称密钥，并使用服务器的公钥进行加密。
3.  **加密通信：** 服务器使用私钥解密客户端发送的信息，获取对称密钥。之后的通信都使用这个对称密钥进行加密和解密，确保数据传输的机密性。

通过这个加密过程，HTTPS 提供了更高层次的安全性，防止了中间人攻击和窃听等威胁。

![image-20240426上午122717062](/Users/zhangyuanpu/Library/Application Support/typora-user-images/image-20240426 上午 122717062.png)

### 抓包为什么能抓到 https 的包

抓包工具通常能够捕获到 HTTPS（Hypertext Transfer Protocol Secure）流量的原因主要是因为它们在设备或操作系统上进行了一些特殊的配置，或者使用了一些技术手段来中间代理（Man-in-the-Middle，MitM）HTTPS 连接。

HTTPS 通信本质上是通过 SSL/TLS 加密的，这意味着在正常情况下，抓包工具是无法直接解析和查看 HTTPS 通信内容的。然而，由于一些合法的用途（例如调试、安全分析），或者不合法的用途（例如恶意攻击），用户可能会使用一些方法来劫持或中间代理 HTTPS 流量，以便进行内容查看或修改。

一些常见的方法包括：

1. **代理服务器：** 用户在设备上配置了代理服务器，将所有的网络流量通过代理进行转发。抓包工具就可以作为代理，捕获所有经过的数据包。这种方式通常需要在设备上安装抓包工具提供的证书，以解密 SSL/TLS 通信。

2. **证书劫持：** 在一些情况下，用户可能会在设备上安装了抓包工具提供的根证书。由于 HTTPS 的加密是建立在信任 SSL/TLS 证书链的基础上的，通过安装抓包工具提供的根证书，它就能够解密 SSL/TLS 通信，查看 HTTPS 请求和响应的内容。

### 发送方与接收方的滑动窗口分为哪几部分

发送方的滑动窗口是用于流控制和拥塞控制的一种机制，用于控制同时发送给接收方的未被确认的数据量。滑动窗口被分为以下几个部分：

1. **发送窗口（Send Window）：** 发送窗口是实际用于发送数据的窗口部分。它指的是允许发送方发送的数据序列号范围。发送窗口的大小由流控制和拥塞控制机制动态调整，通常受到接收方的通告窗口大小和网络拥塞程度的影响。

2. **已发送未确认（Sent Unacknowledged）：** 已发送未确认是指发送方已经发送出去但尚未收到接收方确认的数据。这个部分的大小等于发送窗口的大小。

3. **已发送并且已确认（Sent and Acknowledged）：** 已发送并且已确认是指发送方已经发送出去并且已经收到接收方确认的数据。在接收到确认后，对应的数据就从发送方的滑动窗口中移出。

4. **未发送但已被接收方通告的（Unsent But Acknowledged）：** 未发送但已被接收方通告的是指发送方尚未发送出去，但接收方已经通告允许发送的数据范围。这个范围是发送方可以在未来发送的数据。

5. **未发送且未被通告的（Unsent and Not Acknowledged）：** 未发送且未被通告的是指尚未被发送出去，而且接收方也尚未通告允许发送的数据范围的数据。

接收方的滑动窗口通常分为三个部分，用于管理接收缓冲区中的数据：

1. **已接收且已确认的部分（Received and Acknowledged）：**
   - 这是已经成功接收且已发送确认的数据部分。接收方将通过确认号来告知发送方，这部分数据已经成功接收。
2. **已接收但尚未确认的部分（Received but Not Acknowledged）：**
   - 这是接收方已经接收但尚未发送确认的数据部分。在滑动窗口中，这是接收方可以接收的数据范围，但还未向发送方发送确认。
3. **未接收的部分（Not Received）：**
   - 这是接收方还未接收到的数据部分。在滑动窗口中，这是接收方还能够接收的未确认的数据范围。
